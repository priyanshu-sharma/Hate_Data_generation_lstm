{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.nlp import *\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('processed_final_ws_hate', 'rb') as fp:\n",
    "    data = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>tweet_punct</th>\n",
       "      <th>tweet_pre</th>\n",
       "      <th>tweet_tokenized</th>\n",
       "      <th>tweet_nonstop</th>\n",
       "      <th>tweet_stemmed</th>\n",
       "      <th>tweet_lemmatized</th>\n",
       "      <th>tweet_clean</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>81624</th>\n",
       "      <td>I was advised earlier that such a redirect is ...</td>\n",
       "      <td>I was advised earlier that such a redirect is ...</td>\n",
       "      <td>advised earlier redirect desired option disamb...</td>\n",
       "      <td>[advised, earlier, redirect, desired, option, ...</td>\n",
       "      <td>[advised, earlier, redirect, desired, option, ...</td>\n",
       "      <td>[advis, earlier, redirect, desir, option, disa...</td>\n",
       "      <td>[advised, earlier, redirect, desired, option, ...</td>\n",
       "      <td>[advis, earlier, redirect, desir, option, disa...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75269</th>\n",
       "      <td>Please refrain from adding nonsense to Wikiped...</td>\n",
       "      <td>Please refrain from adding nonsense to Wikiped...</td>\n",
       "      <td>please refrain adding nonsense wikipedia banan...</td>\n",
       "      <td>[please, refrain, adding, nonsense, wikipedia,...</td>\n",
       "      <td>[please, refrain, adding, nonsense, wikipedia,...</td>\n",
       "      <td>[pleas, refrain, ad, nonsens, wikipedia, banan...</td>\n",
       "      <td>[please, refrain, adding, nonsense, wikipedia,...</td>\n",
       "      <td>[pleas, refrain, ad, nonsens, wikipedia, banan...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19022</th>\n",
       "      <td>RT @fukkitsbrittney: @AustinBedsaul is so wise...</td>\n",
       "      <td>RT fukkitsbrittney AustinBedsaul is so wise ye...</td>\n",
       "      <td>rt fukkitsbrittney austinbedsaul wise yet youn...</td>\n",
       "      <td>[rt, fukkitsbrittney, austinbedsaul, wise, yet...</td>\n",
       "      <td>[rt, fukkitsbrittney, austinbedsaul, wise, yet...</td>\n",
       "      <td>[rt, fukkitsbrittney, austinbedsaul, wise, yet...</td>\n",
       "      <td>[rt, fukkitsbrittney, austinbedsaul, wise, yet...</td>\n",
       "      <td>[rt, fukkitsbrittney, austinbedsaul, wise, yet...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80367</th>\n",
       "      <td>You can post me messages here.</td>\n",
       "      <td>You can post me messages here</td>\n",
       "      <td>post messages</td>\n",
       "      <td>[post, messages]</td>\n",
       "      <td>[post, messages]</td>\n",
       "      <td>[post, messag]</td>\n",
       "      <td>[post, message]</td>\n",
       "      <td>[post, messag]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111607</th>\n",
       "      <td>On Southwest Airlines you</td>\n",
       "      <td>On Southwest Airlines you</td>\n",
       "      <td>southwest airlines</td>\n",
       "      <td>[southwest, airlines]</td>\n",
       "      <td>[southwest, airlines]</td>\n",
       "      <td>[southwest, airlin]</td>\n",
       "      <td>[southwest, airline]</td>\n",
       "      <td>[southwest, airlin]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    tweet  \\\n",
       "81624   I was advised earlier that such a redirect is ...   \n",
       "75269   Please refrain from adding nonsense to Wikiped...   \n",
       "19022   RT @fukkitsbrittney: @AustinBedsaul is so wise...   \n",
       "80367                      You can post me messages here.   \n",
       "111607                          On Southwest Airlines you   \n",
       "\n",
       "                                              tweet_punct  \\\n",
       "81624   I was advised earlier that such a redirect is ...   \n",
       "75269   Please refrain from adding nonsense to Wikiped...   \n",
       "19022   RT fukkitsbrittney AustinBedsaul is so wise ye...   \n",
       "80367                       You can post me messages here   \n",
       "111607                          On Southwest Airlines you   \n",
       "\n",
       "                                                tweet_pre  \\\n",
       "81624   advised earlier redirect desired option disamb...   \n",
       "75269   please refrain adding nonsense wikipedia banan...   \n",
       "19022   rt fukkitsbrittney austinbedsaul wise yet youn...   \n",
       "80367                                       post messages   \n",
       "111607                                 southwest airlines   \n",
       "\n",
       "                                          tweet_tokenized  \\\n",
       "81624   [advised, earlier, redirect, desired, option, ...   \n",
       "75269   [please, refrain, adding, nonsense, wikipedia,...   \n",
       "19022   [rt, fukkitsbrittney, austinbedsaul, wise, yet...   \n",
       "80367                                    [post, messages]   \n",
       "111607                              [southwest, airlines]   \n",
       "\n",
       "                                            tweet_nonstop  \\\n",
       "81624   [advised, earlier, redirect, desired, option, ...   \n",
       "75269   [please, refrain, adding, nonsense, wikipedia,...   \n",
       "19022   [rt, fukkitsbrittney, austinbedsaul, wise, yet...   \n",
       "80367                                    [post, messages]   \n",
       "111607                              [southwest, airlines]   \n",
       "\n",
       "                                            tweet_stemmed  \\\n",
       "81624   [advis, earlier, redirect, desir, option, disa...   \n",
       "75269   [pleas, refrain, ad, nonsens, wikipedia, banan...   \n",
       "19022   [rt, fukkitsbrittney, austinbedsaul, wise, yet...   \n",
       "80367                                      [post, messag]   \n",
       "111607                                [southwest, airlin]   \n",
       "\n",
       "                                         tweet_lemmatized  \\\n",
       "81624   [advised, earlier, redirect, desired, option, ...   \n",
       "75269   [please, refrain, adding, nonsense, wikipedia,...   \n",
       "19022   [rt, fukkitsbrittney, austinbedsaul, wise, yet...   \n",
       "80367                                     [post, message]   \n",
       "111607                               [southwest, airline]   \n",
       "\n",
       "                                              tweet_clean  class  \n",
       "81624   [advis, earlier, redirect, desir, option, disa...      0  \n",
       "75269   [pleas, refrain, ad, nonsens, wikipedia, banan...      0  \n",
       "19022   [rt, fukkitsbrittney, austinbedsaul, wise, yet...      1  \n",
       "80367                                      [post, messag]      0  \n",
       "111607                                [southwest, airlin]      0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 199004 entries, 81624 to 14601\n",
      "Data columns (total 9 columns):\n",
      "tweet               199004 non-null object\n",
      "tweet_punct         199004 non-null object\n",
      "tweet_pre           199004 non-null object\n",
      "tweet_tokenized     199004 non-null object\n",
      "tweet_nonstop       199004 non-null object\n",
      "tweet_stemmed       199004 non-null object\n",
      "tweet_lemmatized    199004 non-null object\n",
      "tweet_clean         199004 non-null object\n",
      "class               199004 non-null int64\n",
      "dtypes: int64(1), object(8)\n",
      "memory usage: 15.2+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(199004, 9)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>tweet_punct</th>\n",
       "      <th>tweet_pre</th>\n",
       "      <th>tweet_tokenized</th>\n",
       "      <th>tweet_nonstop</th>\n",
       "      <th>tweet_stemmed</th>\n",
       "      <th>tweet_lemmatized</th>\n",
       "      <th>tweet_clean</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>112436</th>\n",
       "      <td>Joke \\n\\nI said nothing wrong, I was talking a...</td>\n",
       "      <td>Joke \\n\\nI said nothing wrong I was talking ab...</td>\n",
       "      <td>joke said nothing wrong talking posting real a...</td>\n",
       "      <td>[joke, said, nothing, wrong, talking, posting,...</td>\n",
       "      <td>[joke, said, nothing, wrong, talking, posting,...</td>\n",
       "      <td>[joke, said, noth, wrong, talk, post, real, ar...</td>\n",
       "      <td>[joke, said, nothing, wrong, talking, posting,...</td>\n",
       "      <td>[joke, said, noth, wrong, talk, post, real, ar...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65966</th>\n",
       "      <td>these pictures are very old and are of not jat...</td>\n",
       "      <td>these pictures are very old and are of not jat...</td>\n",
       "      <td>pictures old jatts may low castes portraying j...</td>\n",
       "      <td>[pictures, old, jatts, may, low, castes, portr...</td>\n",
       "      <td>[pictures, old, jatts, may, low, castes, portr...</td>\n",
       "      <td>[pictur, old, jatt, may, low, cast, portray, j...</td>\n",
       "      <td>[picture, old, jatts, may, low, caste, portray...</td>\n",
       "      <td>[pictur, old, jatt, may, low, cast, portray, j...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32499</th>\n",
       "      <td>Just when you thought they couldn't possibly g...</td>\n",
       "      <td>Just when you thought they couldnt possibly ge...</td>\n",
       "      <td>thought couldnt possibly get dumber</td>\n",
       "      <td>[thought, couldnt, possibly, get, dumber]</td>\n",
       "      <td>[thought, couldnt, possibly, get, dumber]</td>\n",
       "      <td>[thought, couldnt, possibl, get, dumber]</td>\n",
       "      <td>[thought, couldnt, possibly, get, dumber]</td>\n",
       "      <td>[thought, couldnt, possibl, get, dumber]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148983</th>\n",
       "      <td>if it doesn't get lifted</td>\n",
       "      <td>if it doesnt get lifted</td>\n",
       "      <td>doesnt get lifted</td>\n",
       "      <td>[doesnt, get, lifted]</td>\n",
       "      <td>[doesnt, get, lifted]</td>\n",
       "      <td>[doesnt, get, lift]</td>\n",
       "      <td>[doesnt, get, lifted]</td>\n",
       "      <td>[doesnt, get, lift]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33201</th>\n",
       "      <td>User:They call me Mr. Pibb User:Saturation2 My...</td>\n",
       "      <td>UserThey call me Mr Pibb UserSaturation My con...</td>\n",
       "      <td>userthey call mr pibb usersaturation concern u...</td>\n",
       "      <td>[userthey, call, mr, pibb, usersaturation, con...</td>\n",
       "      <td>[userthey, call, mr, pibb, usersaturation, con...</td>\n",
       "      <td>[userthey, call, mr, pibb, usersatur, concern,...</td>\n",
       "      <td>[userthey, call, mr, pibb, usersaturation, con...</td>\n",
       "      <td>[userthey, call, mr, pibb, usersatur, concern,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    tweet  \\\n",
       "112436  Joke \\n\\nI said nothing wrong, I was talking a...   \n",
       "65966   these pictures are very old and are of not jat...   \n",
       "32499   Just when you thought they couldn't possibly g...   \n",
       "148983                           if it doesn't get lifted   \n",
       "33201   User:They call me Mr. Pibb User:Saturation2 My...   \n",
       "\n",
       "                                              tweet_punct  \\\n",
       "112436  Joke \\n\\nI said nothing wrong I was talking ab...   \n",
       "65966   these pictures are very old and are of not jat...   \n",
       "32499   Just when you thought they couldnt possibly ge...   \n",
       "148983                            if it doesnt get lifted   \n",
       "33201   UserThey call me Mr Pibb UserSaturation My con...   \n",
       "\n",
       "                                                tweet_pre  \\\n",
       "112436  joke said nothing wrong talking posting real a...   \n",
       "65966   pictures old jatts may low castes portraying j...   \n",
       "32499                 thought couldnt possibly get dumber   \n",
       "148983                                  doesnt get lifted   \n",
       "33201   userthey call mr pibb usersaturation concern u...   \n",
       "\n",
       "                                          tweet_tokenized  \\\n",
       "112436  [joke, said, nothing, wrong, talking, posting,...   \n",
       "65966   [pictures, old, jatts, may, low, castes, portr...   \n",
       "32499           [thought, couldnt, possibly, get, dumber]   \n",
       "148983                              [doesnt, get, lifted]   \n",
       "33201   [userthey, call, mr, pibb, usersaturation, con...   \n",
       "\n",
       "                                            tweet_nonstop  \\\n",
       "112436  [joke, said, nothing, wrong, talking, posting,...   \n",
       "65966   [pictures, old, jatts, may, low, castes, portr...   \n",
       "32499           [thought, couldnt, possibly, get, dumber]   \n",
       "148983                              [doesnt, get, lifted]   \n",
       "33201   [userthey, call, mr, pibb, usersaturation, con...   \n",
       "\n",
       "                                            tweet_stemmed  \\\n",
       "112436  [joke, said, noth, wrong, talk, post, real, ar...   \n",
       "65966   [pictur, old, jatt, may, low, cast, portray, j...   \n",
       "32499            [thought, couldnt, possibl, get, dumber]   \n",
       "148983                                [doesnt, get, lift]   \n",
       "33201   [userthey, call, mr, pibb, usersatur, concern,...   \n",
       "\n",
       "                                         tweet_lemmatized  \\\n",
       "112436  [joke, said, nothing, wrong, talking, posting,...   \n",
       "65966   [picture, old, jatts, may, low, caste, portray...   \n",
       "32499           [thought, couldnt, possibly, get, dumber]   \n",
       "148983                              [doesnt, get, lifted]   \n",
       "33201   [userthey, call, mr, pibb, usersaturation, con...   \n",
       "\n",
       "                                              tweet_clean  class  \n",
       "112436  [joke, said, noth, wrong, talk, post, real, ar...      0  \n",
       "65966   [pictur, old, jatt, may, low, cast, portray, j...      0  \n",
       "32499            [thought, couldnt, possibl, get, dumber]      1  \n",
       "148983                                [doesnt, get, lift]      0  \n",
       "33201   [userthey, call, mr, pibb, usersatur, concern,...      0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.utils import shuffle\n",
    "data = shuffle(data)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "112436    Joke \\n\\nI said nothing wrong, I was talking a...\n",
       "65966     these pictures are very old and are of not jat...\n",
       "32499     Just when you thought they couldn't possibly g...\n",
       "148983                             if it doesn't get lifted\n",
       "33201     User:They call me Mr. Pibb User:Saturation2 My...\n",
       "Name: tweet, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = data['tweet']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(199004,)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = data['class']\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((190000,), (190000,), (9004,), (9004,))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def split_vals(a,n): return a[:n].copy(), a[n:].copy()\n",
    "\n",
    "n_valid = 9004  \n",
    "n_trn = len(df)-n_valid\n",
    "raw_train, raw_valid = split_vals(data, n_trn)\n",
    "X_train, X_valid = split_vals(df, n_trn)\n",
    "y_train, y_valid = split_vals(y, n_trn)\n",
    "\n",
    "X_train.shape, y_train.shape, X_valid.shape, y_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "112436    Joke \\n\\nI said nothing wrong, I was talking a...\n",
       "65966     these pictures are very old and are of not jat...\n",
       "32499     Just when you thought they couldn't possibly g...\n",
       "148983                             if it doesn't get lifted\n",
       "33201     User:They call me Mr. Pibb User:Saturation2 My...\n",
       "Name: tweet, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "138766                    Re:Nonagenarians and Centenarians\n",
       "13308             Niggas actin like hoes most of em bitches\n",
       "112745                              go to hell you gestapo!\n",
       "20983              So some pussy don't cream when they cum?\n",
       "80290     What i believe is that you think you can contr...\n",
       "Name: tweet, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_valid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "112436    0\n",
       "65966     0\n",
       "32499     1\n",
       "148983    0\n",
       "33201     0\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "138766    0\n",
       "13308     1\n",
       "112745    1\n",
       "20983     1\n",
       "80290     0\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_valid.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VECTOR CREATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.setrecursionlimit(15000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "stopword = nltk.corpus.stopwords.words('english')\n",
    "ps = nltk.PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text_lc = \"\".join([word.lower() for word in text if word not in string.punctuation]) # remove puntuation\n",
    "    text_rc = re.sub('[0-9]+', '', text_lc)\n",
    "    tokens = re.split('\\W+', text_rc)    # tokenization\n",
    "    text = [ps.stem(word) for word in tokens if word not in stopword]  # remove stopwords and stemming\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = CountVectorizer(analyzer=clean_text) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer=<function clean_text at 0x7efef9bade18>,\n",
       "        binary=False, decode_error='strict', dtype=<class 'numpy.int64'>,\n",
       "        encoding='utf-8', input='content', lowercase=True, max_df=1.0,\n",
       "        max_features=None, min_df=1, ngram_range=(1, 1), preprocessor=None,\n",
       "        stop_words=None, strip_accents=None,\n",
       "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn = X_train\n",
    "val = X_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_doc = v.fit_transform(trn)\n",
    "val_doc = v.transform(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<190000x206367 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 4443335 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<9004x206367 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 203240 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = v.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['anom', 'anomal', 'anomali', 'anomeneprojector', 'anomi']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab[7000:7005]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NAIVE BAYES "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<190000x206367 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 4443335 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = trn_doc\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn_y = y_train.to_numpy()\n",
    "type(trn_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn_y.reshape(1, 190000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = trn_y\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = x[y==1].sum(0)+1\n",
    "q = x[y==0].sum(0)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[9187,    1,    7, ...,    1,    1,    2]], dtype=int64)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 206367)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[104549,      5,     90, ...,      2,      2,     38]], dtype=int64)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 206367)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = np.log((p/p.sum())/(q/q.sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[-0.61524,  0.20719, -0.73727, ...,  1.12348,  1.12348, -1.12781]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 206367)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = np.log(len(p)/len(q))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_y = y_valid.to_numpy()\n",
    "type(val_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9004,)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 1, ..., 1, 0, 0]])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_y.reshape(1, 9004)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9071523767214571"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_preds = val_doc @ r.T + b\n",
    "preds = pre_preds.T>0\n",
    "(preds==val_y).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LOGISTIC REGRESSION "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<190000x206367 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 4443335 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/spriyanshu723/anaconda3/envs/fastai-cpu/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/spriyanshu723/anaconda3/envs/fastai-cpu/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9303642825410928"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = LogisticRegression(C=1e8, dual=True)\n",
    "m.fit(x, y)\n",
    "preds = m.predict(val_doc)\n",
    "(preds==val_y).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/spriyanshu723/anaconda3/envs/fastai-cpu/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9308085295424255"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = LogisticRegression(C=1e8, dual=True)\n",
    "m.fit(trn_doc.sign(), y)\n",
    "preds = m.predict(val_doc.sign())\n",
    "(preds==val_y).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/spriyanshu723/anaconda3/envs/fastai-cpu/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9419147045757441"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = LogisticRegression(C=0.1, dual=True)\n",
    "m.fit(trn_doc, y)\n",
    "preds = m.predict(val_doc)\n",
    "(preds==val_y).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9424700133274101"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = LogisticRegression(C=0.1, dual=True)\n",
    "m.fit(trn_doc.sign(), y)\n",
    "preds = m.predict(val_doc.sign())\n",
    "(preds==val_y).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRI-GRAM MODEL  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = CountVectorizer(ngram_range=(1,4), max_features=800000, analyzer=clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer=<function clean_text at 0x7efef9bade18>,\n",
       "        binary=False, decode_error='strict', dtype=<class 'numpy.int64'>,\n",
       "        encoding='utf-8', input='content', lowercase=True, max_df=1.0,\n",
       "        max_features=800000, min_df=1, ngram_range=(1, 4),\n",
       "        preprocessor=None, stop_words=None, strip_accents=None,\n",
       "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_doc = vec.fit_transform(trn)\n",
    "val_doc = vec.transform(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<190000x206367 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 4443335 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<9004x206367 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 203240 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = vec.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['anom', 'anomal', 'anomali', 'anomeneprojector', 'anomi']"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab[7000:7005]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = trn_y\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, ..., 1, 0, 0])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<190000x206367 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 4443335 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = trn_doc.sign()\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<9004x206367 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 203240 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_x = val_doc.sign()\n",
    "val_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = x[y==1].sum(0)+1\n",
    "q = x[y==0].sum(0)+1\n",
    "r = np.log((p/p.sum())/(q/q.sum()))\n",
    "b = np.log(len(p)/len(q))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9045979564637938"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_preds = val_x @ r.T + b\n",
    "preds = pre_preds.T>0\n",
    "(preds==val_y).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9424700133274101"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = LogisticRegression(C=0.1, dual=True)\n",
    "m.fit(x,y)\n",
    "preds = m.predict(val_x)\n",
    "(preds==val_y).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 206367)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[-0.39889,  0.41648, -0.4102 , ...,  1.10963,  1.10963, -1.14166]])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0.67106, 1.51662, 0.66352, ..., 3.03323, 3.03323, 0.31929]])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9465792980897378"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_nb = x.multiply(r)\n",
    "m = LogisticRegression(C=0.1, dual=True)\n",
    "m.fit(x_nb,y)\n",
    "\n",
    "val_x_nb = val_x.multiply(r)\n",
    "preds = m.predict(val_x_nb)\n",
    "(preds==val_y).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FAST NBSVM++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "sl = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "md = TextClassifierData.from_bow(trn_doc, trn_y, val_doc, val_y, sl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<fastai.nlp.TextClassifierData at 0x7efef5a5ddd8>"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = md.dotprod_nb_learner()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "465f01ac9ba545e58fb33055ad089708",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1, style=ProgressStyle(description_width='initial…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   <lambda>                       \n",
      "    0      0.081596   0.091149   0.934085  \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([0.09115]), 0.9340848511772546]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.fit(0.02, 1, wds=1e-6, cycle_len=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41c420ff48d84f23892e06e753ab0cf6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1, style=ProgressStyle(description_width='initial…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   <lambda>                       \n",
      "    0      0.077287   0.079697   0.93775   \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([0.0797]), 0.9377498889382496]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.fit(0.02, 1, wds=1e-6, cycle_len=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afe2485013af46148c7b1912e75d8c44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1, style=ProgressStyle(description_width='initial…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   <lambda>                       \n",
      "    0      0.072299   0.076863   0.938638  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([0.07686]), 0.9386383829409152]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.fit(0.02, 1, wds=1e-6, cycle_len=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c61571cb9d348ef842adf94e20588bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1, style=ProgressStyle(description_width='initial…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   <lambda>                       \n",
      "    0      0.069775   0.075707   0.938972  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([0.07571]), 0.9389715681919147]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.fit(0.02, 1, wds=1e-6, cycle_len=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8669bf16f424a0286bedb45a0182071",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1, style=ProgressStyle(description_width='initial…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   <lambda>                       \n",
      "    0      0.066827   0.074677   0.938972  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([0.07468]), 0.9389715681919147]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.fit(0.02, 1, wds=1e-6, cycle_len=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>tweet_punct</th>\n",
       "      <th>tweet_pre</th>\n",
       "      <th>tweet_tokenized</th>\n",
       "      <th>tweet_nonstop</th>\n",
       "      <th>tweet_stemmed</th>\n",
       "      <th>tweet_lemmatized</th>\n",
       "      <th>tweet_clean</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>112436</th>\n",
       "      <td>Joke \\n\\nI said nothing wrong, I was talking a...</td>\n",
       "      <td>Joke \\n\\nI said nothing wrong I was talking ab...</td>\n",
       "      <td>joke said nothing wrong talking posting real a...</td>\n",
       "      <td>[joke, said, nothing, wrong, talking, posting,...</td>\n",
       "      <td>[joke, said, nothing, wrong, talking, posting,...</td>\n",
       "      <td>[joke, said, noth, wrong, talk, post, real, ar...</td>\n",
       "      <td>[joke, said, nothing, wrong, talking, posting,...</td>\n",
       "      <td>[joke, said, noth, wrong, talk, post, real, ar...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65966</th>\n",
       "      <td>these pictures are very old and are of not jat...</td>\n",
       "      <td>these pictures are very old and are of not jat...</td>\n",
       "      <td>pictures old jatts may low castes portraying j...</td>\n",
       "      <td>[pictures, old, jatts, may, low, castes, portr...</td>\n",
       "      <td>[pictures, old, jatts, may, low, castes, portr...</td>\n",
       "      <td>[pictur, old, jatt, may, low, cast, portray, j...</td>\n",
       "      <td>[picture, old, jatts, may, low, caste, portray...</td>\n",
       "      <td>[pictur, old, jatt, may, low, cast, portray, j...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32499</th>\n",
       "      <td>Just when you thought they couldn't possibly g...</td>\n",
       "      <td>Just when you thought they couldnt possibly ge...</td>\n",
       "      <td>thought couldnt possibly get dumber</td>\n",
       "      <td>[thought, couldnt, possibly, get, dumber]</td>\n",
       "      <td>[thought, couldnt, possibly, get, dumber]</td>\n",
       "      <td>[thought, couldnt, possibl, get, dumber]</td>\n",
       "      <td>[thought, couldnt, possibly, get, dumber]</td>\n",
       "      <td>[thought, couldnt, possibl, get, dumber]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148983</th>\n",
       "      <td>if it doesn't get lifted</td>\n",
       "      <td>if it doesnt get lifted</td>\n",
       "      <td>doesnt get lifted</td>\n",
       "      <td>[doesnt, get, lifted]</td>\n",
       "      <td>[doesnt, get, lifted]</td>\n",
       "      <td>[doesnt, get, lift]</td>\n",
       "      <td>[doesnt, get, lifted]</td>\n",
       "      <td>[doesnt, get, lift]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33201</th>\n",
       "      <td>User:They call me Mr. Pibb User:Saturation2 My...</td>\n",
       "      <td>UserThey call me Mr Pibb UserSaturation My con...</td>\n",
       "      <td>userthey call mr pibb usersaturation concern u...</td>\n",
       "      <td>[userthey, call, mr, pibb, usersaturation, con...</td>\n",
       "      <td>[userthey, call, mr, pibb, usersaturation, con...</td>\n",
       "      <td>[userthey, call, mr, pibb, usersatur, concern,...</td>\n",
       "      <td>[userthey, call, mr, pibb, usersaturation, con...</td>\n",
       "      <td>[userthey, call, mr, pibb, usersatur, concern,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    tweet  \\\n",
       "112436  Joke \\n\\nI said nothing wrong, I was talking a...   \n",
       "65966   these pictures are very old and are of not jat...   \n",
       "32499   Just when you thought they couldn't possibly g...   \n",
       "148983                           if it doesn't get lifted   \n",
       "33201   User:They call me Mr. Pibb User:Saturation2 My...   \n",
       "\n",
       "                                              tweet_punct  \\\n",
       "112436  Joke \\n\\nI said nothing wrong I was talking ab...   \n",
       "65966   these pictures are very old and are of not jat...   \n",
       "32499   Just when you thought they couldnt possibly ge...   \n",
       "148983                            if it doesnt get lifted   \n",
       "33201   UserThey call me Mr Pibb UserSaturation My con...   \n",
       "\n",
       "                                                tweet_pre  \\\n",
       "112436  joke said nothing wrong talking posting real a...   \n",
       "65966   pictures old jatts may low castes portraying j...   \n",
       "32499                 thought couldnt possibly get dumber   \n",
       "148983                                  doesnt get lifted   \n",
       "33201   userthey call mr pibb usersaturation concern u...   \n",
       "\n",
       "                                          tweet_tokenized  \\\n",
       "112436  [joke, said, nothing, wrong, talking, posting,...   \n",
       "65966   [pictures, old, jatts, may, low, castes, portr...   \n",
       "32499           [thought, couldnt, possibly, get, dumber]   \n",
       "148983                              [doesnt, get, lifted]   \n",
       "33201   [userthey, call, mr, pibb, usersaturation, con...   \n",
       "\n",
       "                                            tweet_nonstop  \\\n",
       "112436  [joke, said, nothing, wrong, talking, posting,...   \n",
       "65966   [pictures, old, jatts, may, low, castes, portr...   \n",
       "32499           [thought, couldnt, possibly, get, dumber]   \n",
       "148983                              [doesnt, get, lifted]   \n",
       "33201   [userthey, call, mr, pibb, usersaturation, con...   \n",
       "\n",
       "                                            tweet_stemmed  \\\n",
       "112436  [joke, said, noth, wrong, talk, post, real, ar...   \n",
       "65966   [pictur, old, jatt, may, low, cast, portray, j...   \n",
       "32499            [thought, couldnt, possibl, get, dumber]   \n",
       "148983                                [doesnt, get, lift]   \n",
       "33201   [userthey, call, mr, pibb, usersatur, concern,...   \n",
       "\n",
       "                                         tweet_lemmatized  \\\n",
       "112436  [joke, said, nothing, wrong, talking, posting,...   \n",
       "65966   [picture, old, jatts, may, low, caste, portray...   \n",
       "32499           [thought, couldnt, possibly, get, dumber]   \n",
       "148983                              [doesnt, get, lifted]   \n",
       "33201   [userthey, call, mr, pibb, usersaturation, con...   \n",
       "\n",
       "                                              tweet_clean  class  \n",
       "112436  [joke, said, noth, wrong, talk, post, real, ar...      0  \n",
       "65966   [pictur, old, jatt, may, low, cast, portray, j...      0  \n",
       "32499            [thought, couldnt, possibl, get, dumber]      1  \n",
       "148983                                [doesnt, get, lift]      0  \n",
       "33201   [userthey, call, mr, pibb, usersatur, concern,...      0  "
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>tweet_punct</th>\n",
       "      <th>tweet_pre</th>\n",
       "      <th>tweet_tokenized</th>\n",
       "      <th>tweet_nonstop</th>\n",
       "      <th>tweet_stemmed</th>\n",
       "      <th>tweet_lemmatized</th>\n",
       "      <th>tweet_clean</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>32499</th>\n",
       "      <td>Just when you thought they couldn't possibly g...</td>\n",
       "      <td>Just when you thought they couldnt possibly ge...</td>\n",
       "      <td>thought couldnt possibly get dumber</td>\n",
       "      <td>[thought, couldnt, possibly, get, dumber]</td>\n",
       "      <td>[thought, couldnt, possibly, get, dumber]</td>\n",
       "      <td>[thought, couldnt, possibl, get, dumber]</td>\n",
       "      <td>[thought, couldnt, possibly, get, dumber]</td>\n",
       "      <td>[thought, couldnt, possibl, get, dumber]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122304</th>\n",
       "      <td>Welcome back. Here is a crapping cat, a univer...</td>\n",
       "      <td>Welcome back Here is a crapping cat a universa...</td>\n",
       "      <td>welcome back crapping cat universal symbol rel...</td>\n",
       "      <td>[welcome, back, crapping, cat, universal, symb...</td>\n",
       "      <td>[welcome, back, crapping, cat, universal, symb...</td>\n",
       "      <td>[welcom, back, crap, cat, univers, symbol, rel...</td>\n",
       "      <td>[welcome, back, crapping, cat, universal, symb...</td>\n",
       "      <td>[welcom, back, crap, cat, univers, symbol, rel...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2706</th>\n",
       "      <td>@Buckm00se all us beaners were pissed like rob...</td>\n",
       "      <td>Buckmse all us beaners were pissed like robert...</td>\n",
       "      <td>buckmse us beaners pissed like robert jew ref ...</td>\n",
       "      <td>[buckmse, us, beaners, pissed, like, robert, j...</td>\n",
       "      <td>[buckmse, us, beaners, pissed, like, robert, j...</td>\n",
       "      <td>[buckms, us, beaner, piss, like, robert, jew, ...</td>\n",
       "      <td>[buckmse, u, beaner, pissed, like, robert, jew...</td>\n",
       "      <td>[buckms, us, beaner, piss, like, robert, jew, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23196</th>\n",
       "      <td>Yo main bitch that's my side hoe !</td>\n",
       "      <td>Yo main bitch thats my side hoe</td>\n",
       "      <td>yo main bitch thats side hoe</td>\n",
       "      <td>[yo, main, bitch, thats, side, hoe]</td>\n",
       "      <td>[yo, main, bitch, thats, side, hoe]</td>\n",
       "      <td>[yo, main, bitch, that, side, hoe]</td>\n",
       "      <td>[yo, main, bitch, thats, side, hoe]</td>\n",
       "      <td>[yo, main, bitch, that, side, hoe]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2956</th>\n",
       "      <td>You are a raging faggot.  Kill yourself.</td>\n",
       "      <td>You are a raging faggot  Kill yourself</td>\n",
       "      <td>raging faggot kill</td>\n",
       "      <td>[raging, faggot, kill]</td>\n",
       "      <td>[raging, faggot, kill]</td>\n",
       "      <td>[rage, faggot, kill]</td>\n",
       "      <td>[raging, faggot, kill]</td>\n",
       "      <td>[rage, faggot, kill]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    tweet  \\\n",
       "32499   Just when you thought they couldn't possibly g...   \n",
       "122304  Welcome back. Here is a crapping cat, a univer...   \n",
       "2706    @Buckm00se all us beaners were pissed like rob...   \n",
       "23196                  Yo main bitch that's my side hoe !   \n",
       "2956             You are a raging faggot.  Kill yourself.   \n",
       "\n",
       "                                              tweet_punct  \\\n",
       "32499   Just when you thought they couldnt possibly ge...   \n",
       "122304  Welcome back Here is a crapping cat a universa...   \n",
       "2706    Buckmse all us beaners were pissed like robert...   \n",
       "23196                    Yo main bitch thats my side hoe    \n",
       "2956               You are a raging faggot  Kill yourself   \n",
       "\n",
       "                                                tweet_pre  \\\n",
       "32499                 thought couldnt possibly get dumber   \n",
       "122304  welcome back crapping cat universal symbol rel...   \n",
       "2706    buckmse us beaners pissed like robert jew ref ...   \n",
       "23196                        yo main bitch thats side hoe   \n",
       "2956                                   raging faggot kill   \n",
       "\n",
       "                                          tweet_tokenized  \\\n",
       "32499           [thought, couldnt, possibly, get, dumber]   \n",
       "122304  [welcome, back, crapping, cat, universal, symb...   \n",
       "2706    [buckmse, us, beaners, pissed, like, robert, j...   \n",
       "23196                 [yo, main, bitch, thats, side, hoe]   \n",
       "2956                               [raging, faggot, kill]   \n",
       "\n",
       "                                            tweet_nonstop  \\\n",
       "32499           [thought, couldnt, possibly, get, dumber]   \n",
       "122304  [welcome, back, crapping, cat, universal, symb...   \n",
       "2706    [buckmse, us, beaners, pissed, like, robert, j...   \n",
       "23196                 [yo, main, bitch, thats, side, hoe]   \n",
       "2956                               [raging, faggot, kill]   \n",
       "\n",
       "                                            tweet_stemmed  \\\n",
       "32499            [thought, couldnt, possibl, get, dumber]   \n",
       "122304  [welcom, back, crap, cat, univers, symbol, rel...   \n",
       "2706    [buckms, us, beaner, piss, like, robert, jew, ...   \n",
       "23196                  [yo, main, bitch, that, side, hoe]   \n",
       "2956                                 [rage, faggot, kill]   \n",
       "\n",
       "                                         tweet_lemmatized  \\\n",
       "32499           [thought, couldnt, possibly, get, dumber]   \n",
       "122304  [welcome, back, crapping, cat, universal, symb...   \n",
       "2706    [buckmse, u, beaner, pissed, like, robert, jew...   \n",
       "23196                 [yo, main, bitch, thats, side, hoe]   \n",
       "2956                               [raging, faggot, kill]   \n",
       "\n",
       "                                              tweet_clean  class  \n",
       "32499            [thought, couldnt, possibl, get, dumber]      1  \n",
       "122304  [welcom, back, crap, cat, univers, symbol, rel...      1  \n",
       "2706    [buckms, us, beaner, piss, like, robert, jew, ...      1  \n",
       "23196                  [yo, main, bitch, that, side, hoe]      1  \n",
       "2956                                 [rage, faggot, kill]      1  "
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_hate = data.loc[data['class'] == 1]\n",
    "data_hate.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(199004, 9)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39090, 9)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_hate.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>tweet_punct</th>\n",
       "      <th>tweet_pre</th>\n",
       "      <th>tweet_tokenized</th>\n",
       "      <th>tweet_nonstop</th>\n",
       "      <th>tweet_stemmed</th>\n",
       "      <th>tweet_lemmatized</th>\n",
       "      <th>tweet_clean</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>112436</th>\n",
       "      <td>Joke \\n\\nI said nothing wrong, I was talking a...</td>\n",
       "      <td>Joke \\n\\nI said nothing wrong I was talking ab...</td>\n",
       "      <td>joke said nothing wrong talking posting real a...</td>\n",
       "      <td>[joke, said, nothing, wrong, talking, posting,...</td>\n",
       "      <td>[joke, said, nothing, wrong, talking, posting,...</td>\n",
       "      <td>[joke, said, noth, wrong, talk, post, real, ar...</td>\n",
       "      <td>[joke, said, nothing, wrong, talking, posting,...</td>\n",
       "      <td>[joke, said, noth, wrong, talk, post, real, ar...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65966</th>\n",
       "      <td>these pictures are very old and are of not jat...</td>\n",
       "      <td>these pictures are very old and are of not jat...</td>\n",
       "      <td>pictures old jatts may low castes portraying j...</td>\n",
       "      <td>[pictures, old, jatts, may, low, castes, portr...</td>\n",
       "      <td>[pictures, old, jatts, may, low, castes, portr...</td>\n",
       "      <td>[pictur, old, jatt, may, low, cast, portray, j...</td>\n",
       "      <td>[picture, old, jatts, may, low, caste, portray...</td>\n",
       "      <td>[pictur, old, jatt, may, low, cast, portray, j...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148983</th>\n",
       "      <td>if it doesn't get lifted</td>\n",
       "      <td>if it doesnt get lifted</td>\n",
       "      <td>doesnt get lifted</td>\n",
       "      <td>[doesnt, get, lifted]</td>\n",
       "      <td>[doesnt, get, lifted]</td>\n",
       "      <td>[doesnt, get, lift]</td>\n",
       "      <td>[doesnt, get, lifted]</td>\n",
       "      <td>[doesnt, get, lift]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33201</th>\n",
       "      <td>User:They call me Mr. Pibb User:Saturation2 My...</td>\n",
       "      <td>UserThey call me Mr Pibb UserSaturation My con...</td>\n",
       "      <td>userthey call mr pibb usersaturation concern u...</td>\n",
       "      <td>[userthey, call, mr, pibb, usersaturation, con...</td>\n",
       "      <td>[userthey, call, mr, pibb, usersaturation, con...</td>\n",
       "      <td>[userthey, call, mr, pibb, usersatur, concern,...</td>\n",
       "      <td>[userthey, call, mr, pibb, usersaturation, con...</td>\n",
       "      <td>[userthey, call, mr, pibb, usersatur, concern,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104584</th>\n",
       "      <td>So it would be too difficult for you to write ...</td>\n",
       "      <td>So it would be too difficult for you to write ...</td>\n",
       "      <td>would difficult write balanced article take ti...</td>\n",
       "      <td>[would, difficult, write, balanced, article, t...</td>\n",
       "      <td>[would, difficult, write, balanced, article, t...</td>\n",
       "      <td>[would, difficult, write, balanc, articl, take...</td>\n",
       "      <td>[would, difficult, write, balanced, article, t...</td>\n",
       "      <td>[would, difficult, write, balanc, articl, take...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    tweet  \\\n",
       "112436  Joke \\n\\nI said nothing wrong, I was talking a...   \n",
       "65966   these pictures are very old and are of not jat...   \n",
       "148983                           if it doesn't get lifted   \n",
       "33201   User:They call me Mr. Pibb User:Saturation2 My...   \n",
       "104584  So it would be too difficult for you to write ...   \n",
       "\n",
       "                                              tweet_punct  \\\n",
       "112436  Joke \\n\\nI said nothing wrong I was talking ab...   \n",
       "65966   these pictures are very old and are of not jat...   \n",
       "148983                            if it doesnt get lifted   \n",
       "33201   UserThey call me Mr Pibb UserSaturation My con...   \n",
       "104584  So it would be too difficult for you to write ...   \n",
       "\n",
       "                                                tweet_pre  \\\n",
       "112436  joke said nothing wrong talking posting real a...   \n",
       "65966   pictures old jatts may low castes portraying j...   \n",
       "148983                                  doesnt get lifted   \n",
       "33201   userthey call mr pibb usersaturation concern u...   \n",
       "104584  would difficult write balanced article take ti...   \n",
       "\n",
       "                                          tweet_tokenized  \\\n",
       "112436  [joke, said, nothing, wrong, talking, posting,...   \n",
       "65966   [pictures, old, jatts, may, low, castes, portr...   \n",
       "148983                              [doesnt, get, lifted]   \n",
       "33201   [userthey, call, mr, pibb, usersaturation, con...   \n",
       "104584  [would, difficult, write, balanced, article, t...   \n",
       "\n",
       "                                            tweet_nonstop  \\\n",
       "112436  [joke, said, nothing, wrong, talking, posting,...   \n",
       "65966   [pictures, old, jatts, may, low, castes, portr...   \n",
       "148983                              [doesnt, get, lifted]   \n",
       "33201   [userthey, call, mr, pibb, usersaturation, con...   \n",
       "104584  [would, difficult, write, balanced, article, t...   \n",
       "\n",
       "                                            tweet_stemmed  \\\n",
       "112436  [joke, said, noth, wrong, talk, post, real, ar...   \n",
       "65966   [pictur, old, jatt, may, low, cast, portray, j...   \n",
       "148983                                [doesnt, get, lift]   \n",
       "33201   [userthey, call, mr, pibb, usersatur, concern,...   \n",
       "104584  [would, difficult, write, balanc, articl, take...   \n",
       "\n",
       "                                         tweet_lemmatized  \\\n",
       "112436  [joke, said, nothing, wrong, talking, posting,...   \n",
       "65966   [picture, old, jatts, may, low, caste, portray...   \n",
       "148983                              [doesnt, get, lifted]   \n",
       "33201   [userthey, call, mr, pibb, usersaturation, con...   \n",
       "104584  [would, difficult, write, balanced, article, t...   \n",
       "\n",
       "                                              tweet_clean  class  \n",
       "112436  [joke, said, noth, wrong, talk, post, real, ar...      0  \n",
       "65966   [pictur, old, jatt, may, low, cast, portray, j...      0  \n",
       "148983                                [doesnt, get, lift]      0  \n",
       "33201   [userthey, call, mr, pibb, usersatur, concern,...      0  \n",
       "104584  [would, difficult, write, balanc, articl, take...      0  "
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_unhate = data.loc[data['class'] == 0]\n",
    "data_unhate.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(159914, 9)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_unhate.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "199004"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "159914 + 39090"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RETRIVING THE TOP WORDS FROM HATE DATASET "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32499     Just when you thought they couldn't possibly g...\n",
       "122304    Welcome back. Here is a crapping cat, a univer...\n",
       "2706      @Buckm00se all us beaners were pissed like rob...\n",
       "23196                    Yo main bitch that's my side hoe !\n",
       "2956               You are a raging faggot.  Kill yourself.\n",
       "Name: tweet, dtype: object"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hate_df = data_hate['tweet']\n",
    "hate_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39090,)"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hate_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "one = TfidfVectorizer(ngram_range=(1,4),\n",
    "               min_df=3, max_df=0.9, strip_accents='unicode', use_idf=1,\n",
    "               smooth_idf=1, sublinear_tf=1, tokenizer=tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.float64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=0.9, max_features=None, min_df=3,\n",
       "        ngram_range=(1, 4), norm='l2', preprocessor=None, smooth_idf=1,\n",
       "        stop_words=None, strip_accents='unicode', sublinear_tf=1,\n",
       "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=<function tokenize at 0x7eff8e0279d8>, use_idf=1,\n",
       "        vocabulary=None)"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_term_doc = one.fit_transform(hate_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<39090x156376 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 2434763 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn_term_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[': \" that \\'', '? such', 'man , or', 'man , this', '? take a', 'man , you don', 'man , your', 'man . \"', '? sure ,', 'man . i don', 'mama , bitch', \"man . it '\", 'man . the', '? stop being a', 'man @', 'man a', 'man ain', \"man ain '\", \"man , it '\", 'man , it', '? talk \"', 'man , don', 'mama to', 'mama told', 'mama told me', 'mamas', '? that was a', 'man ! ! !', '? that makes', 'man \" \" ,', '? thanks for', '? thanks .', 'man & # 128514', 'man & # 8221', 'man , a', 'man , and', 'man , but', \"man ain ' t\", 'man and he', 'man ass', 'man lol', 'man on', 'man open', 'man open your', 'man open your curtains', 'man rt @', '? so i', \"man that '\", \"man that ' s\", 'man that bitch', 'man the', 'man them', 'man these hoes', 'man these hoes so', '? since you', 'man was a', 'man of', '? so what', 'man because', 'man just', '? stay', 'man cheated', 'man devoting', 'man devoting his', 'man devoting his life', 'man get', 'man http', 'man http :', 'man http : /', '? son of a', '? son of', '? someone who', 'man in a', '? some of', 'man it', 'mama raised', \"mama ' s\", 'in every way', 'making accounts', 'making ,', '? this should all', 'making a formal', 'making a formal complaint', 'making a joke', 'making a point', 'making a total', 'making an', \"mama '\", 'making another', 'making comments', 'making false accusations', '? this should', '? this is the', 'making idiotic', '? this is not', 'makin edits to suit', 'makin edits to', 'makin edits', 'makin a true ass', '? use', 'makes me puke', 'makes me realise', '? ur a', 'makes me wanna', 'makes people', '? u r', '? u need', 'makes these', '? title = wikipedia', '? thought so .', '? thought so', '? those are', 'makin a', 'makin a true', 'making it clear that', 'making it worse', 'making it worse .', 'making your', 'mal', 'malaysians', '? the real', 'males are', 'malfeasance and', 'malibu', 'maliciously', 'malik shabazz', 'mallet', 'malleus is', 'malta', 'malta is', 'malta is an', 'malta is an arab', '? the answer', 'making yourself look like', 'making wikipedia a', 'making life', '? there were', 'making love', '? this is my', 'making me look', 'making me look like', 'making music', '? this is an', 'making non', 'making non -', 'making people', \"making people '\", \"making people ' s\", 'making shit', 'making shit up', 'making sure that', 'making these', 'man what', '? shut', 'man who is', 'mardyks and his', 'maps .', '? oh yeah ,', '? oh well ,', 'march .', 'march 2007', 'march 2013', 'mardyks and', 'mardyks and his kind', 'man why', '? oh right', '? oh no', '? oh i', 'marilyn', '? oh and', '? oh .', 'mario kart', '? ok .', 'map of', 'map .', 'many you want .', 'many parts', 'many parts of', 'many sources', '? once', '? on what', 'many times .', 'many times did', 'many times have', 'many times that', 'many times to', 'many user', 'many users', 'many ways', '? okay ,', 'many you want', 'mark -', 'mark - zuckerberg', 'mark - zuckerberg -', '? nonsense', '? nobody', 'marry you baby', 'marry you baby !', 'martial arts', 'martians', 'martin conway', 'marxist /', 'marxists', 'maryland', '? no . you', 'mask of', '? no , no', '? no !', 'massive penis', 'master . why', 'married -', 'marrie', 'mark - zuckerberg /', 'marriage ?', 'mark .', 'mark arsten', 'mark launched', 'mark launched the', 'mark launched the facebook', 'mark my words', 'mark zuckerberg', 'mark zuckerberg allegedly', 'mark zuckerberg allegedly used', 'mark zuckerberg and', 'mark zuckerberg and a', 'markets', '? now you', 'marley', '? now , i', 'many of us', 'many of them are', '? or is it', 'manhood . my', '? rt \" @', '? rt \"', 'maniac3x : @', 'manic', 'manipulate the', 'manipulation', 'mankind and', '? r', '? quit bangin on', '? quit bangin', 'manner . please', 'manner that', '? plus', '? please tell me', 'manny', 'manhood . my eyes', '? s', 'mansionelan', 'mango', '? should we', 'man without', '? sheesh', 'manage that one', 'manage that one ?', '? seriously ?', 'manage to get', 'management', 'managerarc', 'managerarc ,', 'managerarc , fisherqueen', 'managerarc , fisherqueen (', 'manchester united', 'mandatory', '? section', '? please reply', 'manson', 'many more start .', '? people like', 'many hoes are', 'many hoes are taken', 'many hours', 'many ips', 'many links', 'many links to', 'many many more', 'many many more start', 'many men like', 'many men like to', 'many men will', 'many men will serve', 'many months', '? or the', 'many more start', 'many hoes \"', 'many fucking', '? please explain', 'many followers', 'manual of style', 'manually', 'many \" \"', '? personal', '? peridon ?', '? peridon', 'many accounts', '? people like you', 'many choose', 'many choose to', 'many constructive', 'many different', 'many faithful', 'many faithful girls', 'many faithful girls are', 'makes it worse .', 'makes it clear that', 'makes it clear', 'macktology101 : you', '? zuck : people', 'maccabeez', '? zuck :', '? zuck', 'machine .', \"? you won '\", '? you won', 'macy', 'made the right', '? you will be', 'mad \"', 'mad , and', '? you were', 'mad . .', '? you want to', 'mad at her', 'mabye', 'mabelsay :', 'mabelsay', 'ma smack ya upside', 'm under', 'm waiting', 'm watching', 'm willing', 'm willing to', 'm working on a', '? }', '? |', \"ma ' am ,\", \"ma ' am .\", 'ma main', 'ma nigga', '? zuck : yea', 'ma niggah @', 'ma smack ya', '? you wanna', '? you stupid', 'mad hoes', 'made at', 'made contact', 'made contact with', 'made contact with each', 'made him', 'made his', 'made in the', 'made is', '? you guys', 'made it clear', '? you gotta', 'made me feel', 'made no edits', '? you fuck', '? you dont have', '? you do', '? you know it', 'made another', 'mad or', 'made abundantly', 'mad that i', 'mad when you', 'mad you', 'madamecrystalb', 'maddieevaans', 'made !', 'made \"', 'made &', '? you probably', 'made . .', 'made . my', 'made ?', 'made a joke', '? you make', 'made a twitter', 'm ugly', '@ ! !', 'm too much', 'm on my way', 'm out of', 'm out of here', 'm outside', 'm pissed off', '@ 1stblocjeremiah lol', 'm quite', 'm ready for', 'm ready to', '@ 1stblocjeremiah ctfu', 'm retarded', '@ 1stblocjeremiah : @', 'm saying that', 'm serious .', 'm sick and tired', 'm so mad', 'm one of', '@ 22edham', 'm so sick of', 'm off to', 'm not giving', 'm not gon', 'm not gone', '@ 44binko : @', 'm not new', 'm not retarded', 'm not sure what', 'm not surprised', 'm not the type', '@ 40oz _ van', '@ 40oz _', 'm not you', 'm o', 'm obviously', '@ 40oz', 'm so sick', 'm sorry , but', 'm too busy', 'm takin ya', '@ -', '@ & # 8230', '@ & #', '@ &', 'm the man', 'm the one that', 'm the only one', 'm the pussy', 'm the sockpuppet', 'm the sockpuppet who', 'm the type', 'm thinking', '@ # $ %', 'm tired of you', 'm to', 'm takin ya down', 'm takin', '@ 1bookieg : @', 'm surrounded by', 'm sticking', '@ 100046729 : i', 'm still not', 'm straight', 'm suppose', 'm suppose to', 'm supposed', 'm supposed to', 'm sure ,', 'm sure he', 'm sure it completely', '@ 0beyyourmaster', 'm sure they', 'm sure you can', 'm surrounded', 'made the edit', '? you dahn people', '? user :', 'make sure he', 'make my day !', 'make new', 'make out with', '? what is it', 'make reference', 'make reference to', '? what have', 'make sure that bitch', 'made this ? http', 'make sure that you', 'make sure they', 'make sweet', '? what are you', 'make the article', 'make the most', 'make the rules', 'make me want to', 'make me look bad', '? where are', 'make me laugh !', 'make for you because', 'make friends', '? who the fuck', 'make good', 'make him a', 'make it harder', 'make it out', 'make it sound', 'make it to', 'make jokes', 'make jokes about', 'make love', 'make me get', 'make me go away', 'make me happy', '? what are', '? what an', 'make themselves', 'make you happy', 'make you my', 'make you my bitch', 'make you sound', \"? we ' re\", 'make yourself feel better', 'make yourself look like', 'makem', 'maker .', '? way to', '? way', 'makes an episode', 'makes an episode about', 'makes fun', 'makes fun of', 'makes him feel', '? well , the', 'make you feel like', 'make these', '? well fuck', 'make this a', 'make this place', 'make those', '? what a shame', 'make u happy', 'make u happy later', 'make wikipedia a', 'make wikipedia an', 'make wikipedia an unreliable', '? well that', 'make you a hoe', 'make you cool', 'make you cool ,', 'make you eat', 'make you eat my', 'make for you', 'make for', 'make false', '? you ,', 'magnate', 'magnetism', 'magnetism .', 'magnetism . .', 'magnetism . . .', \"? you ' ve\", 'mah gawd', 'mah page', 'mai', \"? you ' d\", 'mailbox )', 'mailbox ) \"', 'mailman', '? yes you', 'main bitch .', 'magical', 'maggots and', 'main quad', 'maggot . the assyrians', '? you dahn', 'made to be', 'made to the', '? you cant', 'made wikipedia', 'made you an', 'made you the', '? you call', \"? you aren '\", '? you aren', '? you are pathetic', 'mag', '? you are obviously', '? you also', 'maggot . the aramaena', 'main page .', 'main quad ;', 'make everything', 'make a nigga', 'make a stop', 'make a stop in', 'make a valid', 'make a valid point', 'make accusations', 'make an edit ,', '? why is it', '? why cant', 'make any sense .', 'make bitches fly', 'make bitches fly like', 'make changes .', 'make constructive', 'make dat', 'make even', 'make a song', '? why the hell', 'main quad ; now', 'make a lot', 'mains', 'maintain this', 'maintained', 'maintaining an', 'major jenkins his', 'major jenkins his own', 'majority in', 'majority in the', '? without', '? with a', '? will you', 'make - up ,', '? wikipedia is a', '? why would', 'make a bitch', 'master . why don', 'master . your', 'master . your philosophical', 'me how the', 'me happy .', 'me hard', '? do you not', '? do you like', '? do you experience', '? do the', 'me how big', 'me how you', 'me of doing', '? did you read', '? despite', \"me i can '\", 'me i dont care', 'me i need', 'me i should', '? cos', 'me guess . .', 'me guess .', 'me go away .', 'me go away', 'me for saying', 'me for something i', 'me for this', 'me for what', 'me from contributing', 'me from doing', '? does she', 'me from editing !', 'me from editing .', 'me from here', 'me from wikipedia', 'me fuck you ,', 'me give you a', '? do you realize', 'me go ahead', 'me if my', '? come on ,', 'me in that', '? but ,', '? bullshit .', 'me like shit', 'me lolololol cocksucker', '? block', 'me look bad', '? bitch you', 'me making', '? bitch i', 'me more .', 'me motherfucker ugh', 'me never', 'me nigga', 'me niggah !', '? because the', 'me now &', 'me like a man', 'me like \"', '? cant', '? but when', 'me instead', 'me is that', 'me is to', '? calling', '? butthurt ? i', 'me keep', '? butthurt ?', 'me know ,', 'me know and', 'me know if', 'me know when', 'me last night', '? butthurt', '? but when there', 'me laugh . .', 'me for removing', 'me for making', 'me for a weekend', 'me at guttyboy3d', 'me at guttyboy3d or', 'me attitude', '? give me', 'me back i', 'me ban', 'me based', '? get your', 'me be .', 'me be the', '? get off your', 'me because i am', 'me because of my', '? fuckin', '? fuck you ,', 'me behind', 'me at guttyboy3d @', 'me at all', '? finally', 'me as u don', 'me and being', 'me and others', 'me and stop', 'me and that', 'me and this', 'me and your', 'me angry', '? go get a', '? go back to', 'me around wikipedia', '? go back', 'me as \"', 'me as \" \"', 'me as they', 'me as they absently', '? first ,', 'me bitch ,', 'me for ?', 'me cry', '? either way', 'me down .', 'me due to', 'me earlier', 'me editing', 'me even more', 'me ever since', 'me explain', '? dude', 'me feel like', '? dont', 'me for \"', 'me for \" \"', 'me for 24', 'me for 24 hours', '? enjoy', 'me come', '? film', 'me check', \"me bitch i '\", '? fc * k', '? fc *', 'me blocked ,', 'me blocked for', '? fc', 'me but a', '? excuse me', '? excuse', 'me by saying', '? everyone', 'me calling you', 'me can go', 'me can go screw', \"me cause i '\", 'me now if', 'me of personal', 'me and a few', '? ? she', '? ? there', 'me wat', 'me wat to', 'me wat to do', '? ? that bitch', 'me what i can', 'me what is', '? ? seriously', 'me of that', '? ? read the', '? ? read', 'me while i', '? ? quit bangin', 'me why i', 'me why you are', '? ? look', '? ? this', '? ? this is', 'me vandalize', 'me up when', 'me to call', 'me to come', 'me to discuss', 'me to go text', 'me to it', 'me to leave', 'me to put', '? ? wow .', 'me to stop contributing', 'me to tell', 'me to the notice', '? ? why are', 'me try', '? ? what the', 'me up for a', 'me with blocking', 'me with blocking me', '? ? is this', 'mean anything', 'mean bitch', '? ? get a', '? ? fuck', '? ? for', '? ? don', \"mean i ' m\", 'mean i can', 'mean like', 'mean really ,', 'mean shit', 'mean shit to', '? ? and how', 'mean that it', 'mean that they', 'mean that they are', 'mean anything .', 'mean and', 'me without a', '? ? he', 'me wonder', 'me y', 'me ya', '? ? if you', 'me you have', 'me you were', 'me your number', 'me zone', \"me zone '\", \"me zone ' nn\", 'me2', 'meal .', 'mean , seriously', 'mean , seriously ,', '? ? he is', 'me to attack', 'me though', 'me this time too', '? aren', '? are you that', 'me on the goddamn', 'me one ,', 'me one more', 'me one more time', '? are you people', \"me or i '\", 'me or i will', 'me or you', 'me other', '? are u', 'me out of this', 'me over the', 'me personally', 'me proof', 'me on race', 'me on facebook', 'me providing this', 'me on both account', '? asshole', 'me of vandalism ,', 'me of vandalism ?', '? ask', 'me off ! !', '? as for', 'me off and', 'me off for', 'me off that', 'me off this', 'me off this shit', 'me ok', \"? aren ' t\", \"? aren '\", 'me on both', 'me providing', 'me providing this information', 'me thinks', 'me sooo', 'me such', '? all you', 'me that he', '? all the', \"me that i '\", 'me that if', 'me that she', '? all of', 'me that you are', \"? ain ' t\", \"? ain '\", 'me the pussy', 'me them', '? ain', 'me then ,', 'me speak', 'me something : at', 'me realise', 'me something :', 'me rephrase', '? anyhow ,', '? anyhow', 'me sad', '? and you wonder', \"? and you '\", 'me she was', 'me should', 'me sick !', 'me sick , you', 'me sick - a', '? and then', 'me so i don', '? and ,', 'me something ,', 'me and all', 'me and a', 'master of wikipedia ,', 'maya actually say about', '? it took me', 'may you die a', 'may you rot', 'may you rot in', '? it took', 'maya actually', 'maya actually say', 'mayaangeloufro', '? if i don', 'mayaangeloufro :', '? it seems to', 'maybe all', 'maybe even', 'maybe get', 'maybe go', '? it must be', 'may wish to', 'may wish', '? it would', 'may not know', 'may be others', 'may be others of', 'may be some', 'may be the only', 'may even', 'may feel', '? just because wikipedia', 'may have also', 'may have also been', '? jesus h .', '? jesus h', 'may just', '? jesus ,', '? its okay', 'may not be a', '? it must', \"maybe i ' d\", 'maybe i am', '? ima', 'maybe you should do', 'maybe you will', 'maybe you won', \"maybe you won '\", '? if your', 'mayer', 'mayor', '? if you had', 'mcadams', 'mccain', '? if you do', '? if you chose', 'mcgeddon', 'md', '? if this', 'maybe you have', '? indeed', 'maybe i am epf', '? instead', 'maybe i have', '? is this a', '? is there', '? is that what', 'maybe its time', 'maybe its time for', 'maybe next time you', 'maybe not', '? is that the', \"maybe she '\", 'maybe then', '? is that it', 'maybe they just let', 'maybe wikipedia', '? is he', 'may be my', 'may be a little', '? just look at', 'material to', '? make', '? loser !']\n"
     ]
    }
   ],
   "source": [
    "indices_hate = np.argsort(one.idf_)[::-1]\n",
    "features_hate = one.get_feature_names()\n",
    "top_n = 1000\n",
    "top_features_hate = [features_hate[i] for i in indices_hate[:top_n]]\n",
    "print(top_features_hate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
